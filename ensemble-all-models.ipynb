{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['efficientnetpytorchpackage', 'aptos-models', 'aptos2019-blindness-detection']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "os.listdir('/kaggle/input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "package_path = '../input/efficientnetpytorchpackage/EfficientNet-PyTorch-master'\n",
    "sys.path.append(package_path)\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n",
      "1.0.57\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision import *\n",
    "import cv2\n",
    "import fastai\n",
    "\n",
    "\n",
    "print(torch.__version__)\n",
    "print(fastai.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_from_gray(img,tol=7):\n",
    "    if img.ndim ==2:\n",
    "        mask = img>tol\n",
    "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "    elif img.ndim==3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img>tol\n",
    "        \n",
    "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
    "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
    "            return img # return original image\n",
    "        else:\n",
    "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "    #         print(img1.shape,img2.shape,img3.shape)\n",
    "            img = np.stack([img1,img2,img3],axis=-1)\n",
    "    #         print(img.shape)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_prob(arr):\n",
    "    #print(arr.shape)\n",
    "    \n",
    "    probs=torch.zeros(arr.size(0)+1,dtype=arr.dtype)\n",
    "    probs[4]=arr[3]\n",
    "    probs[3]=(arr[2]-arr[3]).relu()\n",
    "    probs[2]=(arr[1]-arr[2]).relu()\n",
    "    probs[1]=(arr[0]-arr[1]).relu()\n",
    "    probs[0]=1-arr[0]\n",
    "\n",
    "    return probs\n",
    "\n",
    "def get_pred(probs):\n",
    "    #print(arr.shape)\n",
    "    return probs.argmax(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clahe(img):\n",
    "    \n",
    "    clahe = cv2.createCLAHE(clipLimit=2 , tileGridSize=(8,8))\n",
    "    img_new_1 = clahe.apply(img[:,:,0])\n",
    "    img_new_2 = clahe.apply(img[:,:,1])\n",
    "    img_new_3 = clahe.apply(img[:,:,2])\n",
    "    img_merge = cv2.merge([img_new_1,img_new_2,img_new_3])\n",
    "    \n",
    "    return img_merge\n",
    "\n",
    "def clahel(img):\n",
    "    \n",
    "    image = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2 , tileGridSize=(8,8))\n",
    "    img_new_1 = clahe.apply(image[:,:,0])\n",
    "    img_merge = cv2.merge([img_new_1,image[:,:,1],image[:,:,2]])\n",
    "    \n",
    "    return cv2.cvtColor(img_merge,cv2.COLOR_LAB2RGB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_load(p,IMG_SIZE=512):\n",
    "    image = cv2.imread(p)\n",
    "    image = crop_image_from_gray(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    height, width = image.shape[:2]\n",
    "    m=max(height,width)\n",
    "    \n",
    "    f=IMG_SIZE/m\n",
    "    image = cv2.resize(image, None,fx=f, fy=f)\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def img_proc(image,blur_rad=10,use_clahel=False,use_clahe=False):\n",
    "    \n",
    "    if(use_clahel==True):\n",
    "        image = clahel(image)\n",
    "    if(use_clahe==True):\n",
    "        image = clahe(image)\n",
    "    \n",
    "    if (blur_rad>0):\n",
    "        image = cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0), blur_rad) ,-4 ,128)\n",
    "    return Image(pil2tensor(image, np.float32).div_(255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'efficientnet_pytorch.model.EfficientNet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "model_path='/kaggle/input/aptos-models/'\n",
    "#No Processing\n",
    "learn1=load_learner(model_path,'finalresnet34-all_train_images_512.pkl')\n",
    "learn2=load_learner(model_path,'finalefficientnet-b6-all_train_images_512.pkl')\n",
    "\n",
    "#Blur=10\n",
    "learn0=load_learner(model_path,'final-rn34-nonzero.pkl')\n",
    "#learn3=load_learner(model_path,'finalresnet34-all_train_images_512_blur.pkl')\n",
    "#learn4=load_learner(model_path,'finalefficientnet-b6-all_train_images_512_blur.pkl')\n",
    "\n",
    "#Clahe\n",
    "learn5=load_learner(model_path,'finalresnet34-all_train_images_512_clahe.pkl')\n",
    "learn6=load_learner(model_path,'finalefficientnet-b6-all_train_images_512_clahe.pkl')\n",
    "\n",
    "#Clahel\n",
    "learn7=load_learner(model_path,'finalresnet34-all_train_images_512_clahel.pkl')\n",
    "learn8=load_learner(model_path,'finalefficientnet-b6-all_train_images_512_clahel.pkl')\n",
    "\n",
    "#Blur=50\n",
    "#learn9=load_learner(model_path,'finalresnet34-all_train_images_512_blur_50.pkl')\n",
    "#learn10=load_learner(model_path,'finalefficientnet-b6-all_train_images_512_blur_50.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005cfc8afb6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>003f0afdcd15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006efc72b638</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00836aaacf06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>009245722fa4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis\n",
       "0  0005cfc8afb6          0\n",
       "1  003f0afdcd15          0\n",
       "2  006efc72b638          0\n",
       "3  00836aaacf06          0\n",
       "4  009245722fa4          0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1928' class='' max='1928', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1928/1928 12:37<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005cfc8afb6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>003f0afdcd15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006efc72b638</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00836aaacf06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>009245722fa4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>009c019a7309</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>010d915e229a</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0111b949947e</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01499815e469</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0167076e7089</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>01c31b10ab99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>01c5ba195207</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>01e4d86b3a30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>020921b796d5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>020f6983114d</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>021c207614d6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0229c0a80d42</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>024d0a225db1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0268f4382c67</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0299d97f31f7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id_code  diagnosis\n",
       "0   0005cfc8afb6          2\n",
       "1   003f0afdcd15          2\n",
       "2   006efc72b638          2\n",
       "3   00836aaacf06          2\n",
       "4   009245722fa4          2\n",
       "5   009c019a7309          2\n",
       "6   010d915e229a          3\n",
       "7   0111b949947e          1\n",
       "8   01499815e469          2\n",
       "9   0167076e7089          0\n",
       "10  01c31b10ab99          1\n",
       "11  01c5ba195207          2\n",
       "12  01e4d86b3a30          1\n",
       "13  020921b796d5          2\n",
       "14  020f6983114d          2\n",
       "15  021c207614d6          2\n",
       "16  0229c0a80d42          2\n",
       "17  024d0a225db1          2\n",
       "18  0268f4382c67          2\n",
       "19  0299d97f31f7          1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE=512\n",
    "\n",
    "\n",
    "test_path='/kaggle/input/aptos2019-blindness-detection/test_images/'\n",
    "for it in progress_bar(sample_df.index):\n",
    "    fns=str(sample_df.id_code[it])+'.png'\n",
    "\n",
    "    p=test_path + fns\n",
    "\n",
    "    image = cv2.imread(p)\n",
    "    image = crop_image_from_gray(image)\n",
    "    height, width = image.shape[:2]    \n",
    "    m=max(height,width)            \n",
    "    f=IMG_SIZE/m\n",
    "    image_no_proc = cv2.resize(image, None,fx=f, fy=f)\n",
    "    image_no_proc = cv2.cvtColor(image_no_proc, cv2.COLOR_BGR2RGB)\n",
    "    image_blur_10=cv2.addWeighted ( image_no_proc,4, cv2.GaussianBlur( image_no_proc , (0,0), 10) ,-4 ,128)\n",
    "    image_clahe = clahe(image_no_proc)\n",
    "    image_clahel = clahel(image_no_proc)\n",
    "    #image_blur_50 = cv2.addWeighted ( image_no_proc,4, cv2.GaussianBlur( image_no_proc , (0,0), 50) ,-4 ,128)\n",
    "\n",
    "    \n",
    "    probs=0\n",
    "    \n",
    "    #no processing\n",
    "    imagef=Image(pil2tensor(image_no_proc, np.float32).div_(255))  \n",
    "    \n",
    "    pred_class,pred_idx,outputs = learn1.predict(imagef)\n",
    "    probs=probs+get_prob(outputs)\n",
    "    \n",
    "    pred_class,pred_idx,outputs = learn2.predict(imagef)\n",
    "    probs=probs+get_prob(outputs)\n",
    "    \n",
    "    #blur=10\n",
    "    imagef=Image(pil2tensor(image_blur_10, np.float32).div_(255))\n",
    "    \n",
    "    pred_class,pred_idx,outputs = learn0.predict(imagef)\n",
    "    probs=probs+get_prob(outputs)\n",
    "    \n",
    "    #pred_class,pred_idx,outputs = learn3.predict(imagef)\n",
    "    #probs=probs+get_prob(outputs)\n",
    "    \n",
    "    #pred_class,pred_idx,outputs = learn4.predict(imagef)\n",
    "    #probs=probs+get_prob(outputs)\n",
    "    \n",
    "    #clahe\n",
    "    imagef=Image(pil2tensor(image_clahe, np.float32).div_(255))\n",
    "    pred_class,pred_idx,outputs = learn5.predict(imagef)\n",
    "    probs=probs+get_prob(outputs)\n",
    "    \n",
    "    pred_class,pred_idx,outputs = learn6.predict(imagef)\n",
    "    probs=probs+get_prob(outputs)\n",
    "    \n",
    "    #clahel\n",
    "    imagef=Image(pil2tensor(image_clahel, np.float32).div_(255))\n",
    "    pred_class,pred_idx,outputs = learn7.predict(imagef)\n",
    "    probs=probs+get_prob(outputs)\n",
    "    \n",
    "    pred_class,pred_idx,outputs = learn8.predict(imagef)\n",
    "    probs=probs+get_prob(outputs)\n",
    "    \n",
    "    #blur=50\n",
    "    \n",
    "    #imagef=Image(pil2tensor(image_blur_50, np.float32).div_(255))\n",
    "    #pred_class,pred_idx,outputs = learn9.predict(imagef)\n",
    "    #probs=probs+get_prob(outputs)\n",
    "    \n",
    "    #pred_class,pred_idx,outputs = learn10.predict(imagef)\n",
    "    #probs=probs+get_prob(outputs)\n",
    "    \n",
    "    preds2=get_pred(probs)\n",
    "    #print(pred_class, pred_idx,outputs[pred_idx])\n",
    "    #sample_df.diagnosis[it]=preds2.numpy()\n",
    "    sample_df.loc[it,'diagnosis']=preds2.numpy()\n",
    "sample_df[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "sample_df.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
